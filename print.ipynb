{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## seiar ####################################\n",
    "def seiar(y, t, beta, psi, nu, kappa, alpha, tau, p, eta, f, epsilon, q, delta):\n",
    "    S, E, I, A, R = y\n",
    "    Lambda = epsilon * E + (1 - q) * I + delta * A\n",
    "    dSdt = -beta * S * Lambda - psi * nu * S\n",
    "    dEdt = beta * S * Lambda - kappa * E\n",
    "    dIdt = p * kappa * E - alpha * I - tau * I\n",
    "    dAdt = (1 - p) * kappa * E - eta * A\n",
    "    dRdt = f * alpha * I + tau * I + eta * A + psi * nu * S\n",
    "    return [dSdt, dEdt, dIdt, dAdt, dRdt]\n",
    "\n",
    "class SeiarEnvironment(gym.Env):\n",
    "    beta: float\n",
    "    psi: float\n",
    "    nu_daily_max: float\n",
    "    nu_total_max: float\n",
    "    kappa: float\n",
    "    alpha: float\n",
    "    tau: float\n",
    "    p: float\n",
    "    eta: float\n",
    "    f: float\n",
    "    epsilon: float\n",
    "    q: float\n",
    "    delta: float\n",
    "    S0: float\n",
    "    E0: float\n",
    "    I0: float\n",
    "    A0: float\n",
    "    R0: float\n",
    "    tf: float\n",
    "    continuous: bool\n",
    "    RepN: float\n",
    "    def __init__(self, beta, psi, nu_daily_max, nu_total_max, kappa, alpha,\n",
    "                 tau, p, eta, f, epsilon, q, delta,\n",
    "                 S0, E0, I0, A0, R0, tf, dt, continuous, RepN):\n",
    "        super(SeiarEnvironment, self).__init__()\n",
    "        self.beta = beta\n",
    "        self.psi = psi\n",
    "        self.nu_daily_max = nu_daily_max\n",
    "        self.nu_total_max = nu_total_max\n",
    "        self.nu_min = 0.0\n",
    "        self.kappa = kappa\n",
    "        self.alpha = alpha\n",
    "        self.tau = tau\n",
    "        self.p = p\n",
    "        self.eta = eta\n",
    "        self.f = f\n",
    "        self.epsilon = epsilon\n",
    "        self.q = q\n",
    "        self.delta = delta\n",
    "        self.S0 = S0\n",
    "        self.E0 = E0\n",
    "        self.I0 = I0\n",
    "        self.A0 = A0\n",
    "        self.R0 = R0\n",
    "        self.tf = tf\n",
    "        self.dt = dt\n",
    "        self.time = 0\n",
    "        self.days = [self.time]\n",
    "        self.history = [[S0, E0, I0, A0, R0]]\n",
    "        self.nus = []\n",
    "        self.rewards = []\n",
    "        self.continuous = continuous\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=np.inf, shape=(5,), dtype=np.float32)\n",
    "        if self.continuous:\n",
    "            self.action_space = gym.spaces.Box(low=-1, high=1, shape=(1,), dtype=np.float32)\n",
    "        else:\n",
    "            # for dqn \n",
    "            self.action_space = gym.spaces.Discrete(2)\n",
    "\n",
    "    def reset(self):\n",
    "        self.time = 0\n",
    "        self.days = [self.time]\n",
    "        self.state = np.array([self.S0, self.E0, self.I0, self.A0, self.R0])\n",
    "        self.nus = []\n",
    "        self.rewards = []\n",
    "        self.history = [self.state]\n",
    "        return np.array(self.state, dtype=np.float32), {}\n",
    "\n",
    "    def action2control(self, action):\n",
    "        nu = self.nu_min + (self.nu_daily_max - self.nu_min) * (action[0] + 1.0) / 2.0\n",
    "        return nu\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.continuous:\n",
    "            nu = self.action2control(action)\n",
    "        else:\n",
    "            nu = self.nu_min if action == 0 else self.nu_daily_max\n",
    "        self.nus.append(nu)\n",
    "        S0, E0, I0, A0, R0 = self.state\n",
    "        sol = odeint(seiar, [min(0, S0-nu), E0, I0, A0, R0], \n",
    "                     np.linspace(0, self.dt, 101),\n",
    "                     args=(self.beta, self.psi, 0,\n",
    "                           self.kappa, self.alpha, self.tau, \n",
    "                           self.p, self.eta, self.f, self.epsilon,\n",
    "                           self.q, self.delta))\n",
    "\n",
    "        self.time += self.dt\n",
    "        new_state = sol[-1, :]\n",
    "        S, E, I, A, R = new_state\n",
    "        self.state = new_state\n",
    "\n",
    "        reward = - I - nu\n",
    "        if np.sum(self.nus) > self.nu_total_max:\n",
    "            reward -= 1000\n",
    "        reward *= self.dt\n",
    "\n",
    "        self.rewards.append(reward)\n",
    "        self.days.append(self.time)\n",
    "        self.history.append([S, E, I, A, R])\n",
    "\n",
    "        done = True if self.time >= self.tf else False\n",
    "        return (np.array(new_state, dtype=np.float32), reward, done, False, {})\n",
    "    \n",
    "    @property\n",
    "    def dynamics(self):\n",
    "        df = pd.DataFrame(dict(\n",
    "                                days=self.days,\n",
    "                                susceptible=[s[0] for s in self.history],\n",
    "                                infected=[s[2] for s in self.history],\n",
    "                                nus=self.nus + [None],\n",
    "                                rewards=self.rewards + [None])\n",
    "\n",
    "                        )\n",
    "        return df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
